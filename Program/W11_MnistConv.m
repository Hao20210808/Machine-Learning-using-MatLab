%% Mainclear allImages = loadMNISTImages('t10k-images.idx3-ubyte');Images = reshape(Images, 28, 28, []);Labels = loadMNISTLabels('t10k-labels.idx1-ubyte');Labels(Labels == 0) = 10; % 0-->10 rng(1);% Learning% W1 = 1e-2*randn([9 9 20]);W5 = (2*rand(100, 2000) -1)*sqrt(6) / sqrt(360 + 2000);Wo = (2*rand(10, 100) - 1)*sqrt(6) / sqrt(10+100);X = Images(:, :, 1:8000);D = Labels(1:8000); for epoch = 1:3 % trains the network three times    epoch    [W1, W5, Wo] = MnistConv(W1, W5, Wo, X, D);endsave('W11_MnistConv.mat');% Test%X = Images(:, :, 8001:10000);D = Labels(8001:10000);acc = 0;N = length(D);for k = 1:N    x = X(:, :, k); % Input, 28x28    y1 = Conv(x, W1); % Convolution, 20x20x20    y2 = ReLU(y1);    y3 = Pool(y2); % Pool, 10x10x20    y4 = reshape(y3, [], 1); % 2000    v5 = W5*y4; % ReLU, 360    y5 = ReLU(v5);    v = Wo*y5; % Softmax, 10    y = Softmax(v);    [~, i] = max(y);    if i == D(k)        acc = acc+1;    endendacc = acc / N;fprintf('Accuracy is %f\n', acc)%% Convfunction y = Conv(x, W)    [wrow, wcol, numFilters] = size(W);    [xrow, xcol,~] = size(x);        yrow = xrow - wrow +1;    ycol = xcol - wcol +1;        y = zeros(yrow, ycol, numFilters);    for k = 1:numFilters        filter = W(:, :, k);        filter = rot90(squeeze(filter), 2);        y(:, :, k) = conv2(x, filter,'valid');    endend%% Poolingfunction y = Pool(x)    [xrow, xcol, numFilters]=size(x);    y = zeros(xrow/2, xcol/2, numFilters);    filter = ones(2) / (2*2); % for mean    for k = 1:numFilters        image = conv2(x(:, :, k), filter,'valid');        y(:, :, k) = image(1:2:end, 1:2:end);    endend%% ReLUfunction y = ReLU(x)    y = max(0, x);end%% Softmaxfunction y = Softmax(x)    ex = exp(x);    y = ex / sum(ex);end%% MnistConvfunction [W1, W5, Wo] = MnistConv(W1, W5, Wo, X, D)% MnistConv trains the network via the minibatch method     alpha = 0.01;    beta = 0.95;        momentum1 = zeros(size(W1));    momentum5 = zeros(size(W5));    momentumo = zeros(size(Wo));     N = length(D);    bsize = 100; % The number of batches,% we have a total 8,000 training images% The variable blist contains the location of the first training data point to be brought into the minibatch.     blist = 1:bsize:(N-bsize +1);% blist = [ 1, 101, 201, 301, ..., 7801, 7901]% One epoch loop    for batch = 1:length(blist)        dW1 = zeros(size(W1));        dW5 = zeros(size(W5));        dWo = zeros(size(Wo));% Mini - batch loop        begin = blist(batch);        for k = begin : begin + bsize - 135 % Forward pass = inference             x = X(:, :, k); % Input, 28x28            y1 = Conv(x, W1); % Convolution, 20x20x20            y2 = ReLU(y1) ;            y3 = Pool(y2); % Pool, 10x10x20            y4 = reshape(y3, [], 1); % 2000            v5 =  W5*y4; % ReLU, 360            y5 = ReLU(v5);             v = Wo*y5; % Softmax, 10            y = Softmax(v); % the final output of the...network            % One-hot encoding                         d = zeros(10, 1);            d(sub2ind(size(d), D(k), 1)) = 1;                        % Backpropagation            e = d - y;               % Output layer            delta = e;            e5 = Wo'*delta; % Hidden(ReLU) layer            delta5 = (y5>0) .*e5;            e4 = W5'*delta5; % Pooling layer            e3 = reshape(e4, size(y3));            e2 = zeros(size(y2));            W3 = ones(size(y2)) / (2*2);                             for c = 1:20                e2(:, :, c) = kron(e3(:, :, c), ones([2 2])) .*W3(:, :,c);            end                        delta2 = (y2>0) .*e2; % ReLU layer            delta1x = zeros(size(W1)); % Convolutional layer                             for c = 1:20                delta1x(:, :, c) = conv2(x(:, :), rot90(delta2(:, :, c), 2) ,'valid');            end                             dW1 = dW1 + delta1x;            dW5 = dW5+ delta5*y4';            dWo  =  dWo + delta*y5';        end% Update weights:% the weight update is calculated for every 100th...data point.% the weights are adjusted 80(= 8,000/100) times...for every epoch.         dW1 = dW1 / bsize;        dW5 = dW5 / bsize;        dWo = dWo / bsize;% adjusts the weights using momentum         momentum1 = alpha*dW1 + beta*momentum1;        W1 = W1 + momentum1;        momentum5 = alpha*dW5 + beta*momentum5;        W5 = W5 + momentum5;        momentumo = alpha*dWo + beta*momentumo;        Wo = Wo + momentumo;    endend%% loadMNISTImages% reference:https://www.twblogs.net/a/5b8d9ff52b717718833f76f6function images = loadMNISTImages(filename)    %loadMNISTImages returns a 28x28x[number of MNIST images] matrix containing    %the raw MNIST images        fp = fopen(filename, 'rb');    assert(fp ~= -1, ['Could not open ', filename, '']);        magic = fread(fp, 1, 'int32', 0, 'ieee-be');    assert(magic == 2051, ['Bad magic number in ', filename, '']);        numImages = fread(fp, 1, 'int32', 0, 'ieee-be');    numRows = fread(fp, 1, 'int32', 0, 'ieee-be');    numCols = fread(fp, 1, 'int32', 0, 'ieee-be');        images = fread(fp, inf, 'unsigned char');    images = reshape(images, numCols, numRows, numImages);    images = permute(images,[2 1 3]);        fclose(fp);        % Reshape to #pixels x #examples    images = reshape(images, size(images, 1) * size(images, 2), size(images, 3));    % Convert to double and rescale to [0,1]    images = double(images) / 255;end%% loadMNISTLabelsfunction labels = loadMNISTLabels(filename)%loadMNISTLabels returns a [number of MNIST images]x1 matrix containing%the labels for the MNIST images    fp = fopen(filename, 'rb');    assert(fp ~= -1, ['Could not open ', filename, '']);        magic = fread(fp, 1, 'int32', 0, 'ieee-be');    assert(magic == 2049, ['Bad magic number in ', filename, '']);        numLabels = fread(fp, 1, 'int32', 0, 'ieee-be');        labels = fread(fp, inf, 'unsigned char');        assert(size(labels,1) == numLabels, 'Mismatch in label count');        fclose(fp);end